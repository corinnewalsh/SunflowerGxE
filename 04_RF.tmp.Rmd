---
title: "04_RF"
output: html_document
---
## Load libraries
```{r}
library(mctoolsr)
library(plyr) # always load before tidyverse to avoid conflicts with dplyr
library(dplyr)
library(tidyverse) # lazily load all of tidyverse, just in case I want to use it.
library(vegan)
library(caret)
library(randomForest)
library(ranger)
library(Boruta)

#library(forcats) # for neat ordering of factors when graphing
#library(ggrepel) # for making nice repelling labels

set.seed(10)
```

### Set up input and output directories
```{r Set up input and output directories, include = FALSE}
project.fp <- "/Users/coin8046/Desktop/FiererLabNotebook_copy/SunflowerGxE/r_analyses"
raw_data.fp <- file.path(project.fp, "00_raw.data")
clean_data.fp <- file.path(project.fp, "01_clean.data")
    figures_01_clean.fp <- file.path(clean_data.fp, "figures")
    outputs_01_clean.fp <- file.path(clean_data.fp, "outputs")

randfor_04.fp <- file.path(project.fp, "04_RandomForest")
  outputs_04.fp <- file.path(randfor_04.fp, "outputs")
  figures_04.fp <- file.path(randfor_04.fp, "figures")

# if (!dir.exists(randfor_04.fp)) {dir.create(randfor_04.fp, recursive = TRUE)}    
# if (!dir.exists(outputs_04.fp)) {dir.create(outputs_04.fp, recursive = TRUE)}
# if (!dir.exists(figures_04.fp)) {dir.create(figures_04.fp, recursive = TRUE)}

```

### Read in 16S data and make sample dataframes
```{r}
## cleaned data
input_filt <- readRDS(paste0(outputs_01_clean.fp, "/input_filt.RDS"))

## rarefied data
input_rar <- readRDS(paste0(outputs_01_clean.fp, "/input_filt_rar9k.RDS"))

## relative abundance data
input_relab <- readRDS(paste0(outputs_01_clean.fp, "/input_filt_relab.RDS"))
```

### filter to decrease super rare ASVS
```{r}
# remove ASVs found in fewer than 30 samples total
low.tmp <- input_filt$data_loaded %>% 
  mutate(ubiq = rowSums(. !=0)) %>% 
  filter(ubiq < 30)

lowASVs <- row.names(low.tmp)

input_filt.rl <- filter_taxa_from_input(input = input_relab, taxa_IDs_to_remove =  lowASVs)
# < 20:
#13081 taxa removed
#14847 taxa remaining
nrow(input_filt.rl$data_loaded)
# < 30:
# 16968 taxa removed
# 10960 remaining
```

### subset dfs by location 
for location specific 
```{r}
#  "Brookings"           "Burlington"          "Carrington"          "Kirkmeyer"           "Casselton"          
#  "Lindsborg-dryland"   "Lindsborg-irrigated" "Grandin"             "McLaughlin"          "Mandan"             
#  "Pierre"              "Mentor"              "Land Institute"      "Ralls"               "Velva" 

input_Mentor <- filter_data(input = input_filt.rl, filter_cat = "Location", keep_vals = "Mentor")
input_Ralls <- filter_data(input = input_filt.rl, filter_cat = "Location", keep_vals = "Ralls")
input_Kirkmeyer <- filter_data(input = input_filt.rl, filter_cat = "Location", keep_vals = "Kirkmeyer")
input_Mandan <- filter_data(input = input_filt.rl, filter_cat = "Location", keep_vals = "Mandan")
input_Pierre <- filter_data(input = input_filt.rl, filter_cat = "Location", keep_vals = "Pierre")
```




## make initial ML dataframes for splitting then Boruta

```{r}
#input_filt.rl
input <- input_filt.rl

# merge metadata
ASV_rar.tmp <- input$data_loaded %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "sample_id") %>% 
  inner_join(input$map_loaded, by = c("sample_id" = "BoxCell"))

# Remove unecessary metadata
# response variable:"Entry" (or "Average.of.percent.incidence")
ASV_rl.rf <- ASV_rar.tmp %>% 
  column_to_rownames(var = "sample_id") %>% 
  dplyr::select(-c("Sample_type", "Box", "Cell", "CellB", "Location", "sample",
                   "chlorophyll", "subsample_weight_g", "plot", "num", "ReadCount.raw", 
                   "ReadCount.filt", "plot_id", "Plot", "Site", "State.x", "Rep","X","count",
                   "LAT", "LONG", "City", "State.y", "Line.name","Entry"))
  #mutate(Entry = as.factor(Entry))

```

### Separate training and testing data
```{r}
### Separate training and testing data
set.seed(10) #100
random_ordered <- ASV_rl.rf[sample(nrow(ASV_rl.rf)),]
number_training_samples <- ceiling(nrow(random_ordered) * 0.7)
train <- random_ordered[1:number_training_samples,]
test <- random_ordered[(number_training_samples + 1):nrow(random_ordered),]
```


## Boruta feature selection
```{r}
#https://academic.oup.com/bib/article/20/2/492/4554516
#https://www.machinelearningplus.com/machine-learning/feature-selection/

# Perform Boruta search
boruta_output <- Boruta(Entry ~., 
                        data=na.omit(train), doTrace=0) 

boruta_output

boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)

# example of Boruta output for Brookings location
final.Brookings.br <- unique(c("ASV_103","ASV_1068", "ASV_14250", "ASV_14854", "ASV_15242",
                               "ASV_2147",  "ASV_27395", "ASV_335",   "ASV_372",  "ASV_667",
                               "ASV_6966",  "ASV_826", "ASV_1068",  "ASV_13790", "ASV_1411",
                               "ASV_14250", "ASV_14854", "ASV_19545", "ASV_257",   "ASV_4247",
                               "ASV_4661", "ASV_6105",  "ASV_6527" , "ASV_6966",  "ASV_76",
                               "ASV_826","ASV_91","ASV_995","ASV_1068","ASV_12026", "ASV_15242", 
                               "ASV_15575", "ASV_2666",  "ASV_8942",  "ASV_995" ))
```


### final df for random forest input
```{r}
# Brookings
Brookings.rf <- ASV_rar.rf %>% 
  dplyr::select(c(all_of(final.Brookings.br), "Entry"))
```

### Random Forest modeling
```{r}
### Create random forest models
# hyperparameters
fitControl <- trainControl(method = "repeatedcv",
                           number=10, 
                           repeats=3,
                           search='grid')

## Number randomly variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry)

set.seed(10)

### run caret model
caret <- train(Average.of.percent.incidence ~.,
                data=train,
                method = "rf",
                norm.votes=T,
               #type =  
                #predict.all=FALSE,
                #type = "Classification",
               # metric= "",
                ntree = 500,
                tuneGrid=tunegrid,
                trControl = fitControl)
print(caret)
varImp(caret)


### another way to create RF model: Ranger
ranger <- ranger(Entry ~.,
                  data=train,
                  num.trees = 1000,
                  #splitrule = "variance,
                  write.forest = TRUE, 
                  #min.node.size = 5, 
                  classification = FALSE, 
                  seed = 10)
print(ranger)
```

### plots to check ASVs
How does the abundance of ASVs in model relate independently to genotype?
```{r}
# get dataframe in order
Brookings.plt <- Brookings.rf %>% 
  rownames_to_column(var = "sample_id") %>% 
  inner_join(brookings.rl$map_loaded, by = c("sample_id" = "BoxCell")) %>% 
  select(c("ASV_91", "ASV_103", "ASV_1068", "ASV_826", "Entry.y")) %>% 
  pivot_longer(cols = starts_with("ASV"), names_to = "ASV", values_to = "n.reads")

# color palette
loc.pal <-  c("#D53E4F",  "#FDAE61", "#ABDDA4","#9E0142", "#66C2A5", "#3288BD", "#5E4FA2", "#F46D43","#708090", "#5BA9BC")

# plot
bxplt.B <- ggplot(Brookings.plt,
                 aes(x = Entry.y, y = n.reads, color = Entry.y))+
  geom_boxplot()+
  geom_point()+
  facet_wrap(~ASV, scales = "free_y")+ #nrow = 5, ncol = 4
  theme_bw()+  
  scale_color_manual(values = loc.pal)+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
bxplt.B
```

```{r}
#repeat for velva location
velva.rl <- filter_data(input = input_rl_samps, filter_cat = "Location", keep_vals = "Velva")
velva.plt <- velva.rl$data_loaded %>% t() %>% as.data.frame() %>% 
  rownames_to_column(var = "sample_id") %>% 
  inner_join(velva.rl$map_loaded, by = c("sample_id" = "BoxCell")) %>% 
  select(c("ASV_91", "ASV_103", "ASV_1068", "ASV_826", "Entry")) %>% 
  pivot_longer(cols = starts_with("ASV"), names_to = "ASV", values_to = "n.reads")


bxplt.V <- ggplot(velva.plt,
                 aes(x = Entry, y = n.reads, color = Entry))+
  geom_boxplot()+
  geom_point()+
  facet_wrap(~ASV, scales = "free_y")+ #nrow = 5, ncol = 4
  theme_bw()+  
  scale_color_manual(values = loc.pal)+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
bxplt.V
```

